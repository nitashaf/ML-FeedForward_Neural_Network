{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe65057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29badcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this class is merely for encapsulation.\n",
    "#this is how data of the dataset is stores in the objects \n",
    "#of this class.\n",
    "class DataSet:\n",
    "    #name of the dataset\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def set_feature(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def set_classes(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "        \n",
    "    def set_org_data(self, org_data):\n",
    "        self.org_data = org_data\n",
    "        \n",
    "    def get_org_data(self):\n",
    "        return self.org_data\n",
    "    \n",
    "    # not writing all getters, setters, because\n",
    "    # they are not required in python (i didnt know that before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c61a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class reads the data file and the names file\n",
    "#to load inti dataset object\n",
    "class Dataset_Reader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Path = 'C:\\\\Users\\\\nitas\\\\Downloads\\\\Machine Learning 2024\\\\MLProject2\\\\'\n",
    "    \n",
    "    #read the data from data file and fill the Datset class object\n",
    "    def read_data_file(self, ds):\n",
    "        if(ds.name == 'forestfires'):\n",
    "            df = pd.read_csv(self.Path+ds.name+'.data', delimiter=',')\n",
    "        else:    \n",
    "            df = pd.read_csv(self.Path+ds.name+'.data', delimiter=',', header=None)\n",
    "\n",
    "        ds.set_org_data(df)\n",
    "    \n",
    "    \n",
    "    #read name file, naming the features, just to fill\n",
    "    #for results, not mendatory function\n",
    "    def read_attributes(self, ds):\n",
    "        \n",
    "        start_string = 'Attribute Information'\n",
    "        stop_string = 'Missing Attribute Values'\n",
    "        isPrint = False\n",
    "        \n",
    "        #read section, where the file has information \n",
    "        #Attribute Information\n",
    "        with open(Path+ds.name+'.names', 'r') as file:\n",
    "            for line in file:\n",
    "                if start_string in line:\n",
    "                    isPrint = True\n",
    "                    #continue\n",
    "                    \n",
    "                if stop_string in line:\n",
    "                    isPrint = False\n",
    "                    break\n",
    "                        \n",
    "                if isPrint:\n",
    "                    print(line.strip())\n",
    "                        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea596c82",
   "metadata": {},
   "source": [
    "# Pre Processing Class: Demonstration of Ten Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12364246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Process Class, for data cleaning, \n",
    "#checking for any abnormalities, pre processes the data \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class PreProcess:\n",
    "    \n",
    "    def __init__(self, ds):\n",
    "        \n",
    "        #set other values of the Dataset object    \n",
    "        self.set_Dataset_features(ds)\n",
    "        \n",
    "        #min max scaling for the regression datasets\n",
    "        if(ds.type == 'Regression'):\n",
    "            self.min_max_scaling(ds)\n",
    "        if(ds.type == 'Classification'):\n",
    "            self.min_max_scaling_class(ds)\n",
    "        #now first step is to do one-hot encoding\n",
    "        self.one_hot_encoding(ds)\n",
    "        #Now sort the data, if it is not sorted\n",
    "        self.sort_data(ds)\n",
    "        #After this step, we will use only sorted data\n",
    "        self.missing_values(ds)\n",
    "    \n",
    "    \n",
    "    #Zscore Normalization \n",
    "    def zscore_normalization(self, ds):\n",
    "        scaler = StandardScaler()\n",
    "        numeric_cols = ds.org_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        ds.org_data[numeric_cols] = scaler.fit_transform(ds.org_data[numeric_cols])\n",
    "    \n",
    "    \n",
    "    def zscore_normalization_class(self, ds):\n",
    "        scaler = StandardScaler()\n",
    "        numeric_cols = ds.org_data.iloc[:, :-1].select_dtypes(include=['float64', 'int64']).columns\n",
    "        ds.org_data[numeric_cols] = scaler.fit_transform(ds.org_data[numeric_cols])\n",
    "        \n",
    "    #Min max scaling \n",
    "    def min_max_scaling(self, ds):\n",
    "        scaler = MinMaxScaler()\n",
    "        #print(ds.org_data.head())\n",
    "        # Apply scaling only to numeric columns\n",
    "        numeric_cols = ds.org_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        #print(numeric_cols)\n",
    "        ds.org_data[numeric_cols] = scaler.fit_transform(ds.org_data[numeric_cols]) \n",
    "        #print('After applying Min Max Scaling:' ,ds.org_data.head())\n",
    "        #Min max scaling \n",
    "        \n",
    "    #for classification, we will exclude the class column    \n",
    "    def min_max_scaling_class(self, ds):\n",
    "        scaler = MinMaxScaler()\n",
    "        #print(ds.org_data.head())\n",
    "        # Apply scaling only to numeric columns\n",
    "        numeric_cols = ds.org_data.iloc[:, :-1].select_dtypes(include=['float64', 'int64']).columns\n",
    "        #print(numeric_cols)\n",
    "        ds.org_data[numeric_cols] = scaler.fit_transform(ds.org_data[numeric_cols]) \n",
    "        #print('After applying Min Max Scaling:' ,ds.org_data.head())\n",
    "    \n",
    "    #This function sets the no of features and class names\n",
    "    #to the Dataset class object\n",
    "    def set_Dataset_features(self, ds):\n",
    "        #set class names\n",
    "        last_column_unique = ds.org_data.iloc[:, -1].unique()\n",
    "        ds.set_classes(last_column_unique)\n",
    "        #print(ds.get_classes())\n",
    "        \n",
    "        #set no of features, because one column is classes\n",
    "        ds.feature_count = ds.org_data.shape[1] -1\n",
    "        #print(ds.feature_count)\n",
    "    \n",
    "                \n",
    "    #splitting data into 10 parts, Here we will\n",
    "    #implement stratified 10 folds\n",
    "    def split_data_regression(self,ds):\n",
    "        \n",
    "        # first we need to make 10 datasets of consectutive points\n",
    "        #print('\\n Printing the results of 10 folds')\n",
    "        datagroupSize = len(ds.sorted_data) // 10  \n",
    "        print('Fold Size', datagroupSize)\n",
    "        dataGroup = []\n",
    "        \n",
    "        #reusing this part from my first project\n",
    "        for i in range(10):\n",
    "            start = i * datagroupSize\n",
    "            end = start + datagroupSize\n",
    "            if i == 9:  \n",
    "                dataGroup.append(ds.sorted_data.iloc[start:])\n",
    "            else:\n",
    "                dataGroup.append(ds.sorted_data.iloc[start:end])\n",
    "        \n",
    "        \n",
    "        #once we have datasets of sorted data, now we will make folds\n",
    "        #with one point from each fold.\n",
    "        folds = [[] for _ in range(10)]\n",
    "        \n",
    "        max_group_size = max(len(group) for group in dataGroup)\n",
    "        print('Max Fold Size: ',max_group_size)\n",
    "        \n",
    "        # For each index up to the maximum group size\n",
    "        for i in range(max_group_size):\n",
    "            # Loop over the 10 groups\n",
    "            for j in range(10):\n",
    "                #print('fold:', j, 'datagroup :' ,j, 'value',  dataGroup[j].iloc[i, -1])\n",
    "                # Check if the current group has enough data for the current index\n",
    "                if i < len(dataGroup[j]):  \n",
    "                    # Append the i-th example from the j-th group into the j-th fold\n",
    "                    folds[j].append(dataGroup[j].iloc[i])\n",
    "\n",
    "                    \n",
    "        #converting folds into Dataframes\n",
    "        final_folds = folds = [pd.DataFrame(fold) for fold in folds]\n",
    "        ds.ten_folds = final_folds\n",
    "        \n",
    "        #for i in range(10):\n",
    "        #    print(f'Fold {i + 1}:')\n",
    "        #    print(final_folds[i].tail())\n",
    "        \n",
    "        #print(\"Ten Fold Prints\")\n",
    "        #for i, fold in enumerate(final_folds):\n",
    "        #    print(f'Fold {i+1} size: {len(fold)}')\n",
    "        #    print(fold.iloc[:, -1].value_counts())\n",
    "    \n",
    "    \n",
    "    #splitting data into 10 parts, Here we will\n",
    "    #implement stratified 10 folds for classification\n",
    "    def split_data_classification(self,ds):\n",
    "        \n",
    "        #In this we first need to split data accordign to classes\n",
    "        #Since we want the ratio of classes to be same in each fold\n",
    "        classwise_data = {}\n",
    "        \n",
    "        for cls in ds.classes:\n",
    "            classwise_data[cls] = ds.sorted_data[ds.sorted_data.iloc[:, -1] == cls]\n",
    "                    \n",
    "        # Now we will be creating the folds containing data from \n",
    "        # each fold of class, making the ratio same with original data\n",
    "        folds = [[] for _ in range(10)]\n",
    "        \n",
    "        for cls, cls_data in classwise_data.items():\n",
    "            \n",
    "            #first divide the classwise data into 10 parts.\n",
    "            clsPartsforFolds = len(cls_data) //10\n",
    "            clsPartsRemain = len(cls_data) % 10\n",
    "            \n",
    "            #print('Number of class data per fold',clsPartsforFolds)\n",
    "            #print('Remaining data left in class',clsPartsRemain)\n",
    "            #put these values in all folds\n",
    "            start = 0\n",
    "            for i in range(10):\n",
    "                if clsPartsRemain != 0:\n",
    "                    # Add 1 to handle remaining data\n",
    "                    end = start + clsPartsforFolds + 1  \n",
    "                    clsPartsRemain -= 1\n",
    "                else:\n",
    "                    end = start + clsPartsforFolds\n",
    "            \n",
    "                # Append class data slice to the respective fold\n",
    "                folds[i].extend(cls_data.iloc[start:end].values.tolist())\n",
    "                start = end\n",
    "            \n",
    "        \n",
    "        #converting folds into Dataframes\n",
    "        final_folds = [pd.DataFrame(fold, columns=ds.sorted_data.columns) for fold in folds]    \n",
    "        ds.ten_folds = final_folds\n",
    "        \n",
    "        #This section is just to check if the fold created are in the same ratio\n",
    "        #for i in range(10):\n",
    "        #    print(f'Fold {i + 1}:')\n",
    "        #    print(final_folds[i].tail())\n",
    "        \n",
    "        #for i, fold in enumerate(final_folds):\n",
    "        #    print(f'Fold {i+1} size: {len(fold)}')\n",
    "        #    print(fold.iloc[:, -1].value_counts())\n",
    "        \n",
    "    \n",
    "    #added the function to see, if we will need it for any dataset\n",
    "    def one_hot_encoding(self, ds):\n",
    "        #this has first coloumn of categorical data, F, M and I\n",
    "        if(ds.name == 'abalone'):\n",
    "            #save class column and drop it\n",
    "            class_column = ds.org_data.iloc[:, -1]  \n",
    "            ds.org_data = ds.org_data.drop(ds.org_data.columns[-1], axis=1)\n",
    "            \n",
    "            #perform one hot encoding    \n",
    "            first_column_name = ds.org_data.columns[0]\n",
    "            one_hot_encoded = pd.get_dummies(ds.org_data[first_column_name], prefix=first_column_name)\n",
    "            ds.org_data = pd.concat([ds.org_data.drop(columns=[first_column_name]), one_hot_encoded], axis=1)\n",
    "            #append the saved class column to the end again\n",
    "            ds.org_data = pd.concat([ds.org_data, class_column], axis=1)\n",
    "        \n",
    "        #this dataset has first column of manufacturer, and second column of \n",
    "        #model name, which has unique values, so dropping it.\n",
    "        if(ds.name == 'machine'):\n",
    "            \n",
    "            #here i am dropping the last colum, because class / result is \n",
    "            ds.org_data = ds.org_data.drop(ds.org_data.columns[-1], axis=1)\n",
    "            #save the class column and then drop it   \n",
    "            class_column = ds.org_data.iloc[:, -1]\n",
    "            ds.org_data = ds.org_data.drop(ds.org_data.columns[-1], axis=1)\n",
    "            \n",
    "            #drop the second column, which is model number\n",
    "            ds.org_data = ds.org_data.drop(ds.org_data.columns[1], axis=1)\n",
    "            first_column_name = ds.org_data.columns[0]\n",
    "            one_hot_encoded = pd.get_dummies(ds.org_data[first_column_name], prefix=first_column_name)\n",
    "            ds.org_data = pd.concat([ds.org_data.drop(columns=[first_column_name]), one_hot_encoded], axis=1)\n",
    "            \n",
    "            #append the saved class column to the end again\n",
    "            ds.org_data = pd.concat([ds.org_data, class_column], axis=1)\n",
    "        \n",
    "        #first column is months, second column is days\n",
    "        if ds.name == 'forestfires':\n",
    "            \n",
    "            #tranform the last column to log \n",
    "            #*****This is still not helping, we might need normalization*****\n",
    "            ds.org_data['area'] = np.log(ds.org_data['area'] +  1)\n",
    "            \n",
    "            \n",
    "            #save the class column and then drop it, \n",
    "            class_column = ds.org_data.iloc[:, -1]\n",
    "            ds.org_data = ds.org_data.drop(ds.org_data.columns[-1], axis=1)\n",
    "            \n",
    "            first_column_name = ds.org_data.columns[2]\n",
    "            second_column_name = ds.org_data.columns[3]\n",
    "            one_hot_encoded = pd.get_dummies(ds.org_data[[first_column_name, second_column_name]], \n",
    "                                             prefix=[first_column_name, second_column_name])\n",
    "                                    \n",
    "            ds.org_data = pd.concat([ds.org_data.drop(columns=[first_column_name, second_column_name]), \n",
    "                                     one_hot_encoded], axis=1)\n",
    "            \n",
    "            #append the saved class column to the end again\n",
    "            ds.org_data = pd.concat([ds.org_data, class_column], axis=1)\n",
    "        \n",
    "        #print(\"One hot Encoding Step, Resulted data shown below\")\n",
    "        #print(ds.org_data.head())\n",
    "        \n",
    "    #First we need to sort the data, if not sorted according to the \n",
    "    #classes, if data is already sorted, then original values will remain\n",
    "    #same without change\n",
    "    def sort_data(self, ds):\n",
    "        ds.sorted_data = ds.org_data.sort_values(by=ds.org_data.columns[-1])\n",
    "        #and then reset the index\n",
    "        ds.sorted_data = ds.sorted_data.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "    # this function handles missing values, for this project\n",
    "    # forest fires has no missing values\n",
    "    # Abalone has no missing values\n",
    "    # machine has no missing values\n",
    "    # glass has no missing values\n",
    "    # Soybean has no missing values\n",
    "    # breastCancer has missing values\n",
    "    def missing_values(self, ds):      \n",
    "        # Check if any missing values exist, using '?' and null values\n",
    "        ds.sorted_data.replace('?', np.nan, inplace=True)\n",
    "        has_missing_values = ds.sorted_data.isnull().values.any()\n",
    "        missing_values_count = ds.sorted_data.isnull().sum().sum()\n",
    "        \n",
    "        if (has_missing_values):\n",
    "            print(\"This dataset has missing values\")\n",
    "            if missing_values_count > 1:\n",
    "                # It has missing values  \n",
    "                #print(\"This dataset has more missing values\")\n",
    "                rows_with_missing = dds.sorted_data[ds.sorted_data.isnull().any(axis=1)].index\n",
    "                #print(\"Rows with missing values before filling:\")\n",
    "                #print(ds.ds.sorted_data.loc[rows_with_missing])\n",
    "                \n",
    "                if(ds.name == 'breast-cancer-wisconsin'):\n",
    "                    #print(\"Inside the median if\")\n",
    "                    for column in ds.sorted_data.columns[:-1]:\n",
    "                        median_value = ds.sorted_data[column].median()\n",
    "                        # Filling the missing values\n",
    "                        ds.sorted_data[column].fillna(median_value, inplace=True)\n",
    "    \n",
    "                #print(\"Rows with missing values after filling:\")\n",
    "                #print(ds.sorted_data.loc[rows_with_missing])\n",
    "            else:\n",
    "                ds.sorted_data.dropna(inplace=True)\n",
    "                print(\"Dropped the row\")\n",
    "\n",
    "                \n",
    "    #This one function will work for classification    \n",
    "    def split_tuning_data_classification(self, ds):\n",
    "        print('Spliting the data into tunning and remaining')\n",
    "        # Backup sorted data\n",
    "        ds.sorted_data_bk = ds.sorted_data.copy()\n",
    "    \n",
    "        # Initialize empty lists for tuning and remaining data\n",
    "        tuning_data = []\n",
    "        remaining_data = []\n",
    "\n",
    "        # Separate the data into classes\n",
    "        for cls in ds.classes:\n",
    "            #print(cls)\n",
    "            classwise_data = ds.sorted_data[ds.sorted_data.iloc[:, -1] == cls]\n",
    "\n",
    "            # Shuffle the data\n",
    "            classwise_data = classwise_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "            # Extract 10% tuning set\n",
    "            num_tuning_samples = max(1, int(len(classwise_data) * 0.1))  \n",
    "            #print('number of samples from this class',num_tuning_samples )\n",
    "        \n",
    "            # Append tuning set and remaining data\n",
    "            tuning_data.append(classwise_data.iloc[:num_tuning_samples])\n",
    "            remaining_data.append(classwise_data.iloc[num_tuning_samples:])\n",
    "    \n",
    "        # Concatenate tuning and remaining data\n",
    "        ds.tuning_data = pd.concat(tuning_data).reset_index(drop=True)\n",
    "        ds.sorted_data = pd.concat(remaining_data).reset_index(drop=True)\n",
    "        \n",
    "        #print('Length of tuning data:',len(ds.tuning_data) )\n",
    "        #print('Length of remaining data:',len(ds.sorted_data) )\n",
    "        #print('Length of original data:',len(ds.sorted_data_bk) )\n",
    "\n",
    "        \n",
    "    def split_tuning_data_regression(self, ds):\n",
    "        # Backup sorted data\n",
    "        \n",
    "        print('\\n Spliting the data into tunning and remaining')\n",
    "        tuning_fraction = 0.1\n",
    "        n_bins = 10\n",
    "        ds.sorted_data_bk = ds.sorted_data.copy()\n",
    "\n",
    "        # Bin the target variable into quantiles (or any number of bins)\n",
    "        ds.sorted_data['bins'] = pd.qcut(ds.sorted_data.iloc[:, -1], q=n_bins, labels=False, duplicates='drop')\n",
    "\n",
    "        # Initialize empty lists for tuning and remaining data\n",
    "        tuning_data = []\n",
    "        remaining_data = []\n",
    "\n",
    "        # Separate the data into bins (which act as pseudo-classes for stratification)\n",
    "        for bin_value in ds.sorted_data['bins'].unique():\n",
    "            bin_data = ds.sorted_data[ds.sorted_data['bins'] == bin_value]\n",
    "\n",
    "            # Shuffle the data\n",
    "            bin_data = bin_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "            # Extract the specified fraction (10% by default) for the tuning set\n",
    "            num_tuning_samples = int(len(bin_data) * tuning_fraction)\n",
    "\n",
    "            # Append tuning set and remaining data\n",
    "            tuning_data.append(bin_data.iloc[:num_tuning_samples])\n",
    "            remaining_data.append(bin_data.iloc[num_tuning_samples:])\n",
    "\n",
    "        # Concatenate tuning and remaining data\n",
    "        ds.tuning_data = pd.concat(tuning_data).reset_index(drop=True)\n",
    "        ds.sorted_data = pd.concat(remaining_data).reset_index(drop=True)\n",
    "\n",
    "        # Drop the 'bins' column, as it's not needed anymore\n",
    "        ds.sorted_data.drop(columns=['bins'], inplace=True)\n",
    "        ds.tuning_data.drop(columns=['bins'], inplace=True)\n",
    "\n",
    "        # Check lengths\n",
    "        #print('Length of tuning data:', len(ds.tuning_data))\n",
    "        #print('Length of remaining data:', len(ds.sorted_data))\n",
    "        #print('Length of original data:', len(ds.sorted_data_bk))    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "99fe555a",
   "metadata": {},
   "source": [
    "# Layers Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdc8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Layer(ABC): \n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    @abstractmethod\n",
    "    # This is to enforces subclass to implement this method\n",
    "    def forward_propagation(self, inputData):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward_propagation(self, gradient, learning_rate):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b344ae2",
   "metadata": {},
   "source": [
    "# FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b027f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inheritence from abstract class layer\n",
    "class FCHiddenLayer(Layer):\n",
    "    \n",
    "    #the help for initiazing the input randomly has been taken from \n",
    "    #https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        # Random initialization of weights and bias\n",
    "        self.weights = np.random.rand(inputSize, outputSize) - 0.5\n",
    "        self.bias = np.random.rand(1, outputSize) - 0.5\n",
    "\n",
    "    # fully connected layer implementation of forward propagation\n",
    "    # that is input will be multiplied with weights    \n",
    "    def forward_propagation(self, inputData):\n",
    "        # Store the input for backpropagation\n",
    "        self.input = inputData  \n",
    "        \n",
    "        # (inputData * weights) + bias (broadcasted across all rows)\n",
    "        outputData = np.dot(self.input, self.weights) + self.bias\n",
    "        self.output = outputData\n",
    "        \n",
    "        \n",
    "        #print('\\nForward Propagarion of Hidden Layer')\n",
    "        #print(\"Input shape:\", self.input.shape)  \n",
    "        #print(\"output shape:\", self.output.shape)  \n",
    "        #print(\"Weights shape:\", self.weights.shape)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, gradient, learning_rate):\n",
    "        \n",
    "        gradient = np.clip(gradient, -100, 100)\n",
    "        # Ensure the input has 2 dimensions (batch_size, inputSize)\n",
    "        if len(self.input.shape) == 1:\n",
    "            self.input = self.input.reshape(1, -1)\n",
    "\n",
    "        #print('\\nBack Propagarion of Hidden Layer')\n",
    "        #print(\"Input shape:\", self.input.shape)  \n",
    "        #print(\"Gradient shape:\", gradient.shape)  \n",
    "        #print(\"Weights shape:\", self.weights.shape)    \n",
    "                    \n",
    "        # Calculate gradients for weights and inputError (backpropagated error)\n",
    "        inputError = np.dot(gradient, self.weights.T)  \n",
    "        weightsError = np.dot(self.input.T, gradient)  \n",
    "        \n",
    "        # Update weights and bias\n",
    "        self.weights -= learning_rate * weightsError\n",
    "        self.bias -= learning_rate * np.sum(gradient, axis=0, keepdims=True)\n",
    "        return inputError\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acc5d571",
   "metadata": {},
   "source": [
    "# Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7254c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inheritence from abstract class layer\n",
    "class ActivationLayer(Layer):\n",
    "    \n",
    "    # set the  activation function (e.g., sigmoid or tanh)\n",
    "    # set the derivative of the activation function\n",
    "    def __init__(self, activation, activation_derivative):\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "\n",
    "    # here we will not multiply the weights and add bias\n",
    "    # but rather we will use activation function on the data\n",
    "    # returned from fully connected layer\n",
    "    def forward_propagation(self, inputData):\n",
    "\n",
    "        self.input = inputData  \n",
    "        self.output = self.activation(self.input)  # Apply activation to the entire batch\n",
    "        \n",
    "        #print('\\nForward Propagarion of Activation Layer')\n",
    "        #print(\"Input shape:\", self.input.shape)  \n",
    "        #print(\"Output shape:\", self.output.shape)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, gradient, learning_rate):\n",
    "        gradient = np.clip(gradient, -100, 100)\n",
    "        # Apply the derivative of the activation function element-wise\n",
    "        output = self.activation_derivative(self.input) * gradient\n",
    "        \n",
    "        #print('\\nBackward Propagarion of Activation Layer')\n",
    "        #print(\"Gradient shape:\", gradient.shape)  \n",
    "        #print(\"Output shape:\", output.shape)\n",
    "        \n",
    "        return output            \n",
    "    \n",
    "    # Activation functions\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "    # Derivatives of the activation functions\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        sig = ActivationLayer.sigmoid(x)\n",
    "        return np.clip(sig * (1 - sig), 1e-7, 1 - 1e-7)\n",
    "    \n",
    "        \n",
    "    # Linear activation for regression (identity function)\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def linear_derivative(x):\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        exp_vals = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "        return exp_vals / np.sum(exp_vals)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax_derivative(x):\n",
    "        # Assuming we already have softmax output x, softmax derivative is:\n",
    "        return x * (1 - x)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dabb64a",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ce71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, lossFunction=None, lossFunctionDerivative=None):\n",
    "        self.layers = []\n",
    "        self.loss = lossFunction\n",
    "        self.loss_derivative = lossFunctionDerivative\n",
    "\n",
    "    # this will be used for all layers, activation, hidden and output    \n",
    "    def addLayers(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def predict(self, test_features):\n",
    "        rows = len(test_features)\n",
    "        result = []\n",
    "\n",
    "        for i in range(rows):\n",
    "            output = test_features[i]\n",
    "            #this loop will call the forward propagation function of \n",
    "            #each layer, hidden, activation and output\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    #Dealing with mini batches. Also added early stopping on convergence\n",
    "    def train(self, train_features, train_class, epochs, learning_rate, batch_size=32, patience=5):\n",
    "        no_of_samples = len(train_features)\n",
    "        best_loss = float('inf')  # Initialize best_loss to a large value\n",
    "        patience_counter = 0      # Counter to track patience\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            err = 0\n",
    "\n",
    "            # Shuffle the data\n",
    "            indices = np.arange(no_of_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            x_train = train_features[indices]\n",
    "            y_train = train_class[indices]\n",
    "\n",
    "            # Iterate over batches\n",
    "            for j in range(0, no_of_samples, batch_size):\n",
    "                end = min(j + batch_size, no_of_samples)\n",
    "                x_batch = x_train[j:end]\n",
    "                y_batch = y_train[j:end]\n",
    "\n",
    "                # Forward propagation for the whole batch\n",
    "                output = x_batch\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # Calculate the error/loss for the batch\n",
    "                err += self.loss(y_batch, output)\n",
    "\n",
    "                # Find the gradient and backpropagate\n",
    "                error = self.loss_derivative(y_batch, output)\n",
    "                #print(f\"Initial error shape: {error.shape}\")\n",
    "                \n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            err /= no_of_samples  # Average error over the entire dataset\n",
    "            print(f'Epoch {epoch+1}/{epochs}   Error={err:.6f}')\n",
    "\n",
    "            # Early stopping condition\n",
    "            if err < best_loss:\n",
    "                best_loss = err\n",
    "                patience_counter = 0  # Reset patience counter if model improves\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Stopping early at epoch {epoch+1} due to no improvement.')\n",
    "                break\n",
    "\n",
    "    # this the the loss function part, \n",
    "    # mse for regression \n",
    "\n",
    "    @staticmethod\n",
    "    def mse(actual_value, pred_value):\n",
    "        return np.mean(np.power(actual_value-pred_value, 2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_derivative(actual_value, pred_value):\n",
    "        if actual_value.shape != pred_value.shape:\n",
    "            actual_value = actual_value.reshape(pred_value.shape)\n",
    "\n",
    "        #print(f\"After reshaping: actual_value shape: {actual_value.shape}, pred_value shape: {pred_value.shape}\")\n",
    "\n",
    "        return 2 * (pred_value - actual_value) / actual_value.shape[0]\n",
    "\n",
    "    # for classification (binary)\n",
    "    @staticmethod\n",
    "    def binary_crossentropy(actual_value, pred_value):\n",
    "        # Avoid log(0) by clipping values\n",
    "        pred_value = np.clip(pred_value, 1e-12, 1 - 1e-12)\n",
    "        return -np.mean(actual_value * np.log(pred_value) + (1 - actual_value) * np.log(1 - pred_value))\n",
    "\n",
    "    @staticmethod\n",
    "    def binary_crossentropy_derivative(actual_value, pred_value):\n",
    "        # Avoid division by zero\n",
    "        pred_value = np.clip(pred_value, 1e-12, 1 - 1e-12)\n",
    "        return (pred_value - actual_value) / (pred_value * (1 - pred_value) * actual_value.size)\n",
    "\n",
    "\n",
    "    # for multiclass classification\n",
    "    @staticmethod\n",
    "    def categorical_crossentropy(actual_value, pred_value):\n",
    "        # Avoid log(0) by clipping values\n",
    "        pred_value = np.clip(pred_value, 1e-12, 1 - 1e-12)\n",
    "        return -np.mean(np.sum(actual_value * np.log(pred_value), axis=1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_crossentropy_derivative(y_true, y_pred):    \n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clipping to prevent log(0)\n",
    "\n",
    "        return (y_pred - y_true) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08701ce5",
   "metadata": {},
   "source": [
    "#building Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06489d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class ClassificationNet:\n",
    "    def __init__(self):\n",
    "        self.net = None  # Initialize the neural network\n",
    "    \n",
    "    def tuneLearningRate(self, ds, no_of_layers):\n",
    "        best_accuracy = 0\n",
    "        best_lr = None\n",
    "\n",
    "        # Use tuning data for testing and the rest for training\n",
    "        ds.test_data = ds.tuning_data\n",
    "        ds.train_data = pd.concat(ds.ten_folds[:9])\n",
    "\n",
    "        # Split features and labels\n",
    "        train_features = ds.train_data.iloc[:, :-1]\n",
    "        train_cls = ds.train_data.iloc[:, -1]\n",
    "        test_features = ds.test_data.iloc[:, :-1]\n",
    "        test_cls = ds.test_data.iloc[:, -1]\n",
    "\n",
    "        x_train = train_features.to_numpy()\n",
    "        y_train = train_cls.to_numpy()\n",
    "        x_test = test_features.to_numpy()\n",
    "        y_test = test_cls.to_numpy()\n",
    "        input_size = train_features.shape[1]\n",
    "        \n",
    "        #print('Dataset: ', ds.name, ' InputSize:', input_size, 'No of classes:', ds.classes)\n",
    "        \n",
    "        # One-hot encode for labels\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        y_train = encoder.fit_transform(train_cls.values.reshape(-1, 1))  \n",
    "        y_test = encoder.transform(test_cls.values.reshape(-1, 1))  \n",
    "        \n",
    "\n",
    "        # Iterate over learning rates\n",
    "        for lr in [0.001, 0.01, 0.1]:\n",
    "            print(f\"Testing learning rate: {lr}\")\n",
    "            # make neural network\n",
    "            self.makeNeuralNetwork(ds, no_of_layers, input_size)\n",
    "            # train neural network\n",
    "            self.net.train(x_train, y_train, epochs=100, learning_rate=lr)\n",
    "            # get Predictions\n",
    "            predictions = self.net.predict(x_test)\n",
    "            \n",
    "            predictions = np.vstack(predictions) \n",
    "            \n",
    "            if ds.name == 'breast-cancer-wisconsin':\n",
    "                predicted_classes = (predictions > 0.5).astype(int)\n",
    "            else:\n",
    "                predicted_classes = np.argmax(predictions, axis=1)\n",
    "                    \n",
    "            true_classes = np.argmax(y_test, axis=1)\n",
    "            \n",
    "            #print(\"Predictions:\", predictions[:5])  # Inspect predictions\n",
    "            #print(\"Predicted Classes:\", predicted_classes[:5])  # Inspect class predictions\n",
    "            #print(\"True Classes:\", true_classes[:5])  # Inspect true class labels\n",
    "            \n",
    "            \n",
    "            #results = pd.DataFrame({'Actual Class': true_classes, 'Predicted Class': predicted_classes})\n",
    "            #print(results)    \n",
    "\n",
    "            accuracy = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
    "            print(f\"learning rate: {lr}, with accuracy: {accuracy}\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_lr = lr\n",
    "\n",
    "        print(f\"Best learning rate: {best_lr}, with accuracy: {best_accuracy}\")\n",
    "        self.learning_rate = best_lr\n",
    "\n",
    "        \n",
    "    def tuneNoofNeurons(self,ds, no_of_layers):\n",
    "        \n",
    "        best_accuracy = 0\n",
    "        best_lr = None\n",
    "\n",
    "        # Use tuning data for testing and the rest for training\n",
    "        ds.test_data = ds.tuning_data\n",
    "        ds.train_data = pd.concat(ds.ten_folds[:9])\n",
    "\n",
    "        # Split features and labels\n",
    "        train_features = ds.train_data.iloc[:, :-1]\n",
    "        train_cls = ds.train_data.iloc[:, -1]\n",
    "        test_features = ds.test_data.iloc[:, :-1]\n",
    "        test_cls = ds.test_data.iloc[:, -1]\n",
    "\n",
    "        x_train = train_features.to_numpy()\n",
    "        y_train = train_cls.to_numpy()\n",
    "        x_test = test_features.to_numpy()\n",
    "        y_test = test_cls.to_numpy()\n",
    "        input_size = train_features.shape[1]\n",
    "        \n",
    "        #print('Dataset: ', ds.name, ' InputSize:', input_size, 'No of classes:', ds.classes)\n",
    "        \n",
    "        # One-hot encode for labels\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        y_train = encoder.fit_transform(train_cls.values.reshape(-1, 1))  \n",
    "        y_test = encoder.transform(test_cls.values.reshape(-1, 1))  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def makeNeuralNetwork(self, ds, no_of_layers,input_size):\n",
    "        \n",
    "        de_instance =  \n",
    "        \n",
    "        if ds.name == 'breast-cancer-wisconsin':\n",
    "            self.net = NeuralNetwork(NeuralNetwork.binary_crossentropy, \n",
    "                                     NeuralNetwork.binary_crossentropy_derivative)\n",
    "            output_activation = ActivationLayer.sigmoid\n",
    "            output_activation_derivative = ActivationLayer.sigmoid_derivative\n",
    "            output_size = 1  # Binary classification\n",
    "\n",
    "        else:\n",
    "            self.net = NeuralNetwork(NeuralNetwork.categorical_crossentropy, \n",
    "                                     NeuralNetwork.categorical_crossentropy_derivative)\n",
    "            output_activation = ActivationLayer.softmax\n",
    "            output_activation_derivative = ActivationLayer.softmax_derivative\n",
    "            output_size = len(ds.classes) \n",
    "          \n",
    "        if no_of_layers == 0:\n",
    "            \n",
    "            self.net.addLayers(FCHiddenLayer(input_size, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "        \n",
    "        elif no_of_layers == 1:\n",
    "            self.net.addLayers(FCHiddenLayer(input_size, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "\n",
    "        elif no_of_layers == 2:\n",
    "            self.net.addLayers(FCHiddenLayer(input_size, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "\n",
    "    def mainFunction(self, ds, no_of_layers):\n",
    "        fold_accuracies = []\n",
    "\n",
    "        for i in range(len(ds.ten_folds)):  # Assuming len(ds.ten_folds) is 10 for 10-fold CV\n",
    "            # One fold for testing, the rest for training\n",
    "            print(f'Fold: {i}')\n",
    "            ds.test_data = ds.ten_folds[i]\n",
    "            ds.train_data = pd.concat([ds.ten_folds[j] for j in range(10) if j != i])\n",
    "\n",
    "            # Split features and labels\n",
    "            train_features = ds.train_data.iloc[:, :-1]\n",
    "            train_cls = ds.train_data.iloc[:, -1]\n",
    "            test_features = ds.test_data.iloc[:, :-1]\n",
    "            test_cls = ds.test_data.iloc[:, -1]\n",
    "\n",
    "            x_train = train_features.to_numpy()\n",
    "            y_train = train_cls.to_numpy()\n",
    "            x_test = test_features.to_numpy()\n",
    "            y_test = test_cls.to_numpy()\n",
    "            input_size = train_features.shape[1]\n",
    "            \n",
    "            \n",
    "            encoder = OneHotEncoder(sparse_output=False)\n",
    "            y_train = encoder.fit_transform(train_cls.values.reshape(-1, 1))  \n",
    "            y_test = encoder.transform(test_cls.values.reshape(-1, 1))  \n",
    "\n",
    "            # Train the neural network for this fold\n",
    "            self.makeNeuralNetwork(ds, no_of_layers, input_size)\n",
    "            self.net.train(x_train, y_train, epochs=100, learning_rate=self.learning_rate)\n",
    "\n",
    "            predictions = self.net.predict(x_test)\n",
    "            predictions = np.vstack(predictions)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            if ds.name == 'breast-cancer-wisconsin':\n",
    "                predicted_classes = (predictions > 0.5).astype(int)\n",
    "            else:\n",
    "                predicted_classes = np.argmax(predictions, axis=1)\n",
    "                \n",
    "            #Convert one hot encoding back    \n",
    "            true_classes = np.argmax(y_test, axis=1)\n",
    "            \n",
    "            results = pd.DataFrame({'Actual Class': true_classes, 'Predicted Class': predicted_classes})\n",
    "            print(results)\n",
    "            \n",
    "            \n",
    "            accuracy = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
    "\n",
    "            fold_accuracies.append(accuracy)\n",
    "            print(f'Fold: {i}, Accuracy: {accuracy}')\n",
    "\n",
    "        # After all folds, calculate and print the mean accuracy\n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        print(f'Mean Accuracy across all folds: {mean_accuracy}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3040378",
   "metadata": {},
   "source": [
    "#Building regression Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdccf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class RegressionNet:\n",
    "    def __init__(self):\n",
    "        # Initialize the neural network\n",
    "        self.net = None  \n",
    "    \n",
    "    def tuneLearningRate(self, ds, no_of_layers):\n",
    "        \n",
    "        lowest_mse = np.inf  \n",
    "        best_lr = None\n",
    "\n",
    "        # Use tuning data for testing and the rest for training\n",
    "        ds.test_data = ds.tuning_data\n",
    "        ds.train_data = pd.concat(ds.ten_folds[:9])\n",
    "\n",
    "        # Split features and labels\n",
    "        train_features = ds.train_data.iloc[:, :-1]\n",
    "        train_cls = ds.train_data.iloc[:, -1]\n",
    "        test_features = ds.test_data.iloc[:, :-1]\n",
    "        test_cls = ds.test_data.iloc[:, -1]\n",
    "\n",
    "        x_train = train_features.to_numpy()\n",
    "        y_train = train_cls.to_numpy()\n",
    "        x_test = test_features.to_numpy()\n",
    "        y_test = test_cls.to_numpy()\n",
    "        input_size = train_features.shape[1]\n",
    "\n",
    "        print('Dataset: ', ds.name, ' InputSize:', input_size)\n",
    "\n",
    "        # Iterate over learning rates\n",
    "        for lr in [0.001, 0.01, 0.1]:\n",
    "            print(f\"Testing learning rate: {lr}\")\n",
    "            # Make neural network\n",
    "            self.makeNeuralNetwork(ds, no_of_layers, input_size)\n",
    "            # Train neural network\n",
    "            self.net.train(x_train, y_train, epochs=100, learning_rate=lr)\n",
    "            # Get predictions\n",
    "            predictions = self.net.predict(x_test)\n",
    "\n",
    "            results = pd.DataFrame({'Actual Class': y_test, 'Predicted Class': predictions})\n",
    "\n",
    "            # Calculate the error (MSE for regression tasks)\n",
    "            mse = self.mse(results['Actual Class'], results['Predicted Class'])\n",
    "            print(f'Learning Rate: {lr}, with error: {mse}')\n",
    "\n",
    "            # Update the best learning rate if the current MSE is lower\n",
    "            if lowest_mse > mse:\n",
    "                lowest_mse = mse  # Consistent variable usage\n",
    "                best_lr = lr\n",
    "\n",
    "        print(f\"Best learning rate: {best_lr}, with error: {lowest_mse}\")\n",
    "        self.learning_rate = best_lr\n",
    "\n",
    "\n",
    "        \n",
    "    def makeNeuralNetwork(self, ds, no_of_layers,input_size):\n",
    "\n",
    "        self.net = NeuralNetwork(NeuralNetwork.mse, NeuralNetwork.mse_derivative)\n",
    "        output_activation = ActivationLayer.linear\n",
    "        output_activation_derivative = ActivationLayer.linear_derivative\n",
    "        output_size = 1         \n",
    "          \n",
    "        if no_of_layers == 0:\n",
    "            self.net.addLayers(FCHiddenLayer(input_size, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "        \n",
    "        elif no_of_layers == 1:\n",
    "            self.net.addLayers(FCHiddenLayer(input_size, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "\n",
    "        elif no_of_layers == 2:\n",
    "            self.net.addLayers(FCHiddenLayer(input_size, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, 3))\n",
    "            self.net.addLayers(ActivationLayer(ActivationLayer.tanh, ActivationLayer.tanh_derivative))\n",
    "            self.net.addLayers(FCHiddenLayer(3, output_size))\n",
    "            self.net.addLayers(ActivationLayer(output_activation, output_activation_derivative))\n",
    "\n",
    "    def mainFunction(self, ds, no_of_layers):\n",
    "        fold_errors = []\n",
    "\n",
    "        for i in range(len(ds.ten_folds)):  \n",
    "            print(f'Fold: {i}')\n",
    "\n",
    "            # One fold for testing, the rest for training\n",
    "            ds.test_data = ds.ten_folds[i]\n",
    "            ds.train_data = pd.concat([ds.ten_folds[j] for j in range(len(ds.ten_folds)) if j != i])\n",
    "\n",
    "            # Split features and labels\n",
    "            train_features = ds.train_data.iloc[:, :-1]\n",
    "            train_cls = ds.train_data.iloc[:, -1]\n",
    "            test_features = ds.test_data.iloc[:, :-1]\n",
    "            test_cls = ds.test_data.iloc[:, -1]\n",
    "\n",
    "            x_train = train_features.to_numpy()\n",
    "            y_train = train_cls.to_numpy()\n",
    "            x_test = test_features.to_numpy()\n",
    "            y_test = test_cls.to_numpy()\n",
    "            input_size = train_features.shape[1]\n",
    "\n",
    "            # Train the neural network for this fold\n",
    "            self.makeNeuralNetwork(ds, no_of_layers, input_size)\n",
    "            self.net.train(x_train, y_train, epochs=100, learning_rate=self.learning_rate)\n",
    "\n",
    "            predictions = self.net.predict(x_test)\n",
    "            results = pd.DataFrame({'Actual Class': y_test, 'Predicted Class': predictions})\n",
    "\n",
    "            # Calculate the error (MSE for regression tasks)\n",
    "            mse = self.mse(results['Actual Class'], results['Predicted Class'])\n",
    "            print(f'Fold: {i}, Mean Squared Error: {mse}')\n",
    "\n",
    "            # Store fold error\n",
    "            fold_errors.append(mse)\n",
    "\n",
    "            print(f'Fold: {i}, Error: {mse}')\n",
    "\n",
    "        # After all folds, calculate and print the mean error\n",
    "        mean_errors = np.mean(fold_errors)\n",
    "        print(f'Mean Error across all folds: {mean_errors}')\n",
    "\n",
    "        \n",
    "    def mse(self, actual_value, pred_value):\n",
    "        return np.mean(np.power(actual_value - pred_value, 2))\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61686a9b",
   "metadata": {},
   "source": [
    "# Main Driver Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0898a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting the data into tunning and remaining\n",
      "Testing learning rate: 0.001\n",
      "Epoch 1/100   Error=0.173796\n",
      "Epoch 2/100   Error=0.173718\n",
      "Epoch 3/100   Error=0.173891\n",
      "Epoch 4/100   Error=0.174010\n",
      "Epoch 5/100   Error=0.173977\n",
      "Epoch 6/100   Error=0.173985\n",
      "Epoch 7/100   Error=0.174078\n",
      "Stopping early at epoch 7 due to no improvement.\n",
      "learning rate: 0.001, with accuracy: 0.05263157894736842\n",
      "Testing learning rate: 0.01\n",
      "Epoch 1/100   Error=0.175991\n",
      "Epoch 2/100   Error=0.176171\n",
      "Epoch 3/100   Error=0.175975\n",
      "Epoch 4/100   Error=0.176385\n",
      "Epoch 5/100   Error=0.176572\n",
      "Epoch 6/100   Error=0.177148\n",
      "Epoch 7/100   Error=0.177010\n",
      "Epoch 8/100   Error=0.176560\n",
      "Stopping early at epoch 8 due to no improvement.\n",
      "learning rate: 0.01, with accuracy: 0.05263157894736842\n",
      "Testing learning rate: 0.1\n",
      "Epoch 1/100   Error=0.177633\n",
      "Epoch 2/100   Error=0.183806\n",
      "Epoch 3/100   Error=0.260767\n",
      "Epoch 4/100   Error=0.432420\n",
      "Epoch 5/100   Error=0.431123\n",
      "Epoch 6/100   Error=0.447429\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "learning rate: 0.1, with accuracy: 0.3684210526315789\n",
      "Best learning rate: 0.1, with accuracy: 0.3684210526315789\n",
      "Fold: 0\n",
      "Epoch 1/100   Error=0.175205\n",
      "Epoch 2/100   Error=0.176412\n",
      "Epoch 3/100   Error=0.179696\n",
      "Epoch 4/100   Error=0.197071\n",
      "Epoch 5/100   Error=0.349812\n",
      "Epoch 6/100   Error=0.438028\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              0                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             1                1\n",
      "14             2                1\n",
      "15             2                1\n",
      "16             3                1\n",
      "17             3                5\n",
      "18             4                5\n",
      "19             5                1\n",
      "20             5                1\n",
      "21             5                1\n",
      "Fold: 0, Accuracy: 0.3181818181818182\n",
      "Fold: 1\n",
      "Epoch 1/100   Error=0.171860\n",
      "Epoch 2/100   Error=0.171877\n",
      "Epoch 3/100   Error=0.170691\n",
      "Epoch 4/100   Error=0.170159\n",
      "Epoch 5/100   Error=0.171060\n",
      "Epoch 6/100   Error=0.171508\n",
      "Epoch 7/100   Error=0.175937\n",
      "Epoch 8/100   Error=0.182213\n",
      "Epoch 9/100   Error=0.199697\n",
      "Stopping early at epoch 9 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              0                1\n",
      "7              1                1\n",
      "8              1                0\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                0\n",
      "13             1                1\n",
      "14             2                0\n",
      "15             2                1\n",
      "16             3                1\n",
      "17             3                1\n",
      "18             4                0\n",
      "19             5                0\n",
      "20             5                0\n",
      "21             5                0\n",
      "Fold: 1, Accuracy: 0.22727272727272727\n",
      "Fold: 2\n",
      "Epoch 1/100   Error=0.178299\n",
      "Epoch 2/100   Error=0.178880\n",
      "Epoch 3/100   Error=0.181310\n",
      "Epoch 4/100   Error=0.192982\n",
      "Epoch 5/100   Error=0.259488\n",
      "Epoch 6/100   Error=0.276547\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              0                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             1                1\n",
      "14             2                1\n",
      "15             2                1\n",
      "16             3                1\n",
      "17             4                2\n",
      "18             5                1\n",
      "19             5                2\n",
      "20             5                2\n",
      "Fold: 2, Accuracy: 0.3333333333333333\n",
      "Fold: 3\n",
      "Epoch 1/100   Error=0.172235\n",
      "Epoch 2/100   Error=0.173810\n",
      "Epoch 3/100   Error=0.173767\n",
      "Epoch 4/100   Error=0.175189\n",
      "Epoch 5/100   Error=0.179718\n",
      "Epoch 6/100   Error=0.193002\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              1                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             2                1\n",
      "14             2                1\n",
      "15             3                1\n",
      "16             4                1\n",
      "17             5                1\n",
      "18             5                1\n",
      "19             5                1\n",
      "Fold: 3, Accuracy: 0.35\n",
      "Fold: 4\n",
      "Epoch 1/100   Error=0.195098\n",
      "Epoch 2/100   Error=0.329968\n",
      "Epoch 3/100   Error=0.481178\n",
      "Epoch 4/100   Error=0.540219\n",
      "Epoch 5/100   Error=0.560044\n",
      "Epoch 6/100   Error=0.556660\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                3\n",
      "1              0                3\n",
      "2              0                3\n",
      "3              0                3\n",
      "4              0                3\n",
      "5              0                3\n",
      "6              1                3\n",
      "7              1                3\n",
      "8              1                0\n",
      "9              1                3\n",
      "10             1                3\n",
      "11             1                3\n",
      "12             1                3\n",
      "13             2                0\n",
      "14             2                3\n",
      "15             3                0\n",
      "16             4                0\n",
      "17             5                0\n",
      "18             5                0\n",
      "19             5                0\n",
      "Fold: 4, Accuracy: 0.0\n",
      "Fold: 5\n",
      "Epoch 1/100   Error=0.182485\n",
      "Epoch 2/100   Error=0.243760\n",
      "Epoch 3/100   Error=0.447493\n",
      "Epoch 4/100   Error=0.501053\n",
      "Epoch 5/100   Error=0.540052\n",
      "Epoch 6/100   Error=0.529920\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             2                0\n",
      "15             3                4\n",
      "16             4                0\n",
      "17             5                0\n",
      "18             5                0\n",
      "19             5                0\n",
      "Fold: 5, Accuracy: 0.3\n",
      "Fold: 6\n",
      "Epoch 1/100   Error=0.181060\n",
      "Epoch 2/100   Error=0.181702\n",
      "Epoch 3/100   Error=0.183956\n",
      "Epoch 4/100   Error=0.191909\n",
      "Epoch 5/100   Error=0.244492\n",
      "Epoch 6/100   Error=0.444484\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                2\n",
      "1              0                2\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                2\n",
      "5              0                2\n",
      "6              1                2\n",
      "7              1                2\n",
      "8              1                2\n",
      "9              1                2\n",
      "10             1                2\n",
      "11             1                2\n",
      "12             1                2\n",
      "13             2                2\n",
      "14             3                2\n",
      "15             4                2\n",
      "16             5                2\n",
      "17             5                2\n",
      "18             5                2\n",
      "Fold: 6, Accuracy: 0.15789473684210525\n",
      "Fold: 7\n",
      "Epoch 1/100   Error=0.184895\n",
      "Epoch 2/100   Error=0.238977\n",
      "Epoch 3/100   Error=0.412683\n",
      "Epoch 4/100   Error=0.412231\n",
      "Epoch 5/100   Error=0.408333\n",
      "Epoch 6/100   Error=0.422920\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                3\n",
      "1              0                5\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                4\n",
      "5              0                3\n",
      "6              1                5\n",
      "7              1                5\n",
      "8              1                5\n",
      "9              1                5\n",
      "10             1                5\n",
      "11             1                5\n",
      "12             1                1\n",
      "13             2                5\n",
      "14             3                5\n",
      "15             4                5\n",
      "16             5                5\n",
      "17             5                5\n",
      "Fold: 7, Accuracy: 0.16666666666666666\n",
      "Fold: 8\n",
      "Epoch 1/100   Error=0.176107\n",
      "Epoch 2/100   Error=0.184555\n",
      "Epoch 3/100   Error=0.264002\n",
      "Epoch 4/100   Error=0.408465\n",
      "Epoch 5/100   Error=0.419771\n",
      "Epoch 6/100   Error=0.422368\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                5\n",
      "1              0                5\n",
      "2              0                5\n",
      "3              0                5\n",
      "4              0                5\n",
      "5              0                5\n",
      "6              1                5\n",
      "7              1                5\n",
      "8              1                5\n",
      "9              1                5\n",
      "10             1                5\n",
      "11             1                5\n",
      "12             1                5\n",
      "13             2                5\n",
      "14             3                5\n",
      "15             5                5\n",
      "16             5                5\n",
      "Fold: 8, Accuracy: 0.11764705882352941\n",
      "Fold: 9\n",
      "Epoch 1/100   Error=0.178505\n",
      "Epoch 2/100   Error=0.197985\n",
      "Epoch 3/100   Error=0.377628\n",
      "Epoch 4/100   Error=0.446441\n",
      "Epoch 5/100   Error=0.491962\n",
      "Epoch 6/100   Error=0.533008\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             2                0\n",
      "13             3                0\n",
      "14             5                0\n",
      "15             5                0\n",
      "Fold: 9, Accuracy: 0.375\n",
      "Mean Accuracy across all folds: 0.234599634112018\n",
      "Fold: 0\n",
      "Epoch 1/100   Error=0.177366\n",
      "Epoch 2/100   Error=0.178281\n",
      "Epoch 3/100   Error=0.178992\n",
      "Epoch 4/100   Error=0.180833\n",
      "Epoch 5/100   Error=0.188731\n",
      "Epoch 6/100   Error=0.299871\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                4\n",
      "1              0                4\n",
      "2              0                4\n",
      "3              0                4\n",
      "4              0                4\n",
      "5              0                4\n",
      "6              0                4\n",
      "7              1                4\n",
      "8              1                4\n",
      "9              1                4\n",
      "10             1                4\n",
      "11             1                4\n",
      "12             1                4\n",
      "13             1                4\n",
      "14             2                4\n",
      "15             2                4\n",
      "16             3                4\n",
      "17             3                4\n",
      "18             4                4\n",
      "19             5                4\n",
      "20             5                4\n",
      "21             5                4\n",
      "Fold: 0, Accuracy: 0.045454545454545456\n",
      "Fold: 1\n",
      "Epoch 1/100   Error=0.186005\n",
      "Epoch 2/100   Error=0.208163\n",
      "Epoch 3/100   Error=0.519046\n",
      "Epoch 4/100   Error=0.723973\n",
      "Epoch 5/100   Error=0.812209\n",
      "Epoch 6/100   Error=0.813646\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                2\n",
      "1              0                2\n",
      "2              0                2\n",
      "3              0                2\n",
      "4              0                2\n",
      "5              0                2\n",
      "6              0                2\n",
      "7              1                2\n",
      "8              1                2\n",
      "9              1                2\n",
      "10             1                2\n",
      "11             1                2\n",
      "12             1                2\n",
      "13             1                2\n",
      "14             2                2\n",
      "15             2                2\n",
      "16             3                2\n",
      "17             3                2\n",
      "18             4                2\n",
      "19             5                2\n",
      "20             5                2\n",
      "21             5                2\n",
      "Fold: 1, Accuracy: 0.09090909090909091\n",
      "Fold: 2\n",
      "Epoch 1/100   Error=0.177534\n",
      "Epoch 2/100   Error=0.179865\n",
      "Epoch 3/100   Error=0.193591\n",
      "Epoch 4/100   Error=0.363099\n",
      "Epoch 5/100   Error=0.410011\n",
      "Epoch 6/100   Error=0.420782\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              0                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             1                1\n",
      "14             2                1\n",
      "15             2                1\n",
      "16             3                1\n",
      "17             4                1\n",
      "18             5                1\n",
      "19             5                1\n",
      "20             5                1\n",
      "Fold: 2, Accuracy: 0.3333333333333333\n",
      "Fold: 3\n",
      "Epoch 1/100   Error=0.172128\n",
      "Epoch 2/100   Error=0.175053\n",
      "Epoch 3/100   Error=0.197522\n",
      "Epoch 4/100   Error=0.392186\n",
      "Epoch 5/100   Error=0.408816\n",
      "Epoch 6/100   Error=0.412388\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              1                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             2                1\n",
      "14             2                1\n",
      "15             3                1\n",
      "16             4                1\n",
      "17             5                1\n",
      "18             5                1\n",
      "19             5                1\n",
      "Fold: 3, Accuracy: 0.35\n",
      "Fold: 4\n",
      "Epoch 1/100   Error=0.190516\n",
      "Epoch 2/100   Error=0.209387\n",
      "Epoch 3/100   Error=0.490166\n",
      "Epoch 4/100   Error=0.705174\n",
      "Epoch 5/100   Error=0.690375\n",
      "Epoch 6/100   Error=0.704869\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                5\n",
      "1              0                5\n",
      "2              0                5\n",
      "3              0                5\n",
      "4              0                5\n",
      "5              0                5\n",
      "6              1                5\n",
      "7              1                5\n",
      "8              1                5\n",
      "9              1                5\n",
      "10             1                5\n",
      "11             1                5\n",
      "12             1                5\n",
      "13             2                5\n",
      "14             2                5\n",
      "15             3                5\n",
      "16             4                5\n",
      "17             5                5\n",
      "18             5                5\n",
      "19             5                5\n",
      "Fold: 4, Accuracy: 0.15\n",
      "Fold: 5\n",
      "Epoch 1/100   Error=0.177148\n",
      "Epoch 2/100   Error=0.178372\n",
      "Epoch 3/100   Error=0.180296\n",
      "Epoch 4/100   Error=0.183625\n",
      "Epoch 5/100   Error=0.197154\n",
      "Epoch 6/100   Error=0.358720\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                3\n",
      "1              0                3\n",
      "2              0                3\n",
      "3              0                3\n",
      "4              0                3\n",
      "5              0                3\n",
      "6              1                3\n",
      "7              1                3\n",
      "8              1                3\n",
      "9              1                3\n",
      "10             1                3\n",
      "11             1                3\n",
      "12             1                3\n",
      "13             2                3\n",
      "14             2                3\n",
      "15             3                3\n",
      "16             4                3\n",
      "17             5                3\n",
      "18             5                3\n",
      "19             5                3\n",
      "Fold: 5, Accuracy: 0.05\n",
      "Fold: 6\n",
      "Epoch 1/100   Error=0.177929\n",
      "Epoch 2/100   Error=0.206869\n",
      "Epoch 3/100   Error=0.417804\n",
      "Epoch 4/100   Error=0.437648\n",
      "Epoch 5/100   Error=0.451895\n",
      "Epoch 6/100   Error=0.452105\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             3                0\n",
      "15             4                0\n",
      "16             5                0\n",
      "17             5                0\n",
      "18             5                0\n",
      "Fold: 6, Accuracy: 0.3157894736842105\n",
      "Fold: 7\n",
      "Epoch 1/100   Error=0.178330\n",
      "Epoch 2/100   Error=0.178777\n",
      "Epoch 3/100   Error=0.184778\n",
      "Epoch 4/100   Error=0.281907\n",
      "Epoch 5/100   Error=0.439551\n",
      "Epoch 6/100   Error=0.445634\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             3                0\n",
      "15             4                0\n",
      "16             5                0\n",
      "17             5                0\n",
      "Fold: 7, Accuracy: 0.3333333333333333\n",
      "Fold: 8\n",
      "Epoch 1/100   Error=0.170806\n",
      "Epoch 2/100   Error=0.171899\n",
      "Epoch 3/100   Error=0.174497\n",
      "Epoch 4/100   Error=0.181407\n",
      "Epoch 5/100   Error=0.297506\n",
      "Epoch 6/100   Error=0.439295\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                5\n",
      "1              0                5\n",
      "2              0                5\n",
      "3              0                5\n",
      "4              0                5\n",
      "5              0                5\n",
      "6              1                5\n",
      "7              1                5\n",
      "8              1                5\n",
      "9              1                5\n",
      "10             1                5\n",
      "11             1                5\n",
      "12             1                5\n",
      "13             2                5\n",
      "14             3                5\n",
      "15             5                5\n",
      "16             5                5\n",
      "Fold: 8, Accuracy: 0.11764705882352941\n",
      "Fold: 9\n",
      "Epoch 1/100   Error=0.178849\n",
      "Epoch 2/100   Error=0.186685\n",
      "Epoch 3/100   Error=0.298804\n",
      "Epoch 4/100   Error=0.449660\n",
      "Epoch 5/100   Error=0.629244\n",
      "Epoch 6/100   Error=0.677314\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                2\n",
      "1              0                2\n",
      "2              0                2\n",
      "3              0                2\n",
      "4              0                2\n",
      "5              0                2\n",
      "6              1                2\n",
      "7              1                2\n",
      "8              1                2\n",
      "9              1                2\n",
      "10             1                2\n",
      "11             1                2\n",
      "12             2                2\n",
      "13             3                2\n",
      "14             5                2\n",
      "15             5                2\n",
      "Fold: 9, Accuracy: 0.0625\n",
      "Mean Accuracy across all folds: 0.18489668355380431\n",
      "Fold: 0\n",
      "Epoch 1/100   Error=0.180593\n",
      "Epoch 2/100   Error=0.185114\n",
      "Epoch 3/100   Error=0.202026\n",
      "Epoch 4/100   Error=0.490563\n",
      "Epoch 5/100   Error=0.805451\n",
      "Epoch 6/100   Error=0.823753\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                2\n",
      "1              0                2\n",
      "2              0                2\n",
      "3              0                2\n",
      "4              0                2\n",
      "5              0                2\n",
      "6              0                2\n",
      "7              1                2\n",
      "8              1                2\n",
      "9              1                2\n",
      "10             1                2\n",
      "11             1                2\n",
      "12             1                2\n",
      "13             1                2\n",
      "14             2                2\n",
      "15             2                2\n",
      "16             3                2\n",
      "17             3                2\n",
      "18             4                2\n",
      "19             5                2\n",
      "20             5                2\n",
      "21             5                2\n",
      "Fold: 0, Accuracy: 0.09090909090909091\n",
      "Fold: 1\n",
      "Epoch 1/100   Error=0.176413\n",
      "Epoch 2/100   Error=0.176220\n",
      "Epoch 3/100   Error=0.176868\n",
      "Epoch 4/100   Error=0.178710\n",
      "Epoch 5/100   Error=0.186739\n",
      "Epoch 6/100   Error=0.234903\n",
      "Epoch 7/100   Error=0.272000\n",
      "Stopping early at epoch 7 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              0                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             1                0\n",
      "14             2                0\n",
      "15             2                0\n",
      "16             3                0\n",
      "17             3                0\n",
      "18             4                0\n",
      "19             5                0\n",
      "20             5                0\n",
      "21             5                0\n",
      "Fold: 1, Accuracy: 0.3181818181818182\n",
      "Fold: 2\n",
      "Epoch 1/100   Error=0.175808\n",
      "Epoch 2/100   Error=0.176722\n",
      "Epoch 3/100   Error=0.176870\n",
      "Epoch 4/100   Error=0.178913\n",
      "Epoch 5/100   Error=0.183450\n",
      "Epoch 6/100   Error=0.201808\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              0                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             1                1\n",
      "14             2                1\n",
      "15             2                1\n",
      "16             3                1\n",
      "17             4                1\n",
      "18             5                1\n",
      "19             5                1\n",
      "20             5                1\n",
      "Fold: 2, Accuracy: 0.3333333333333333\n",
      "Fold: 3\n",
      "Epoch 1/100   Error=0.177661\n",
      "Epoch 2/100   Error=0.178345\n",
      "Epoch 3/100   Error=0.179552\n",
      "Epoch 4/100   Error=0.184196\n",
      "Epoch 5/100   Error=0.239553\n",
      "Epoch 6/100   Error=0.449442\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             2                0\n",
      "15             3                0\n",
      "16             4                0\n",
      "17             5                0\n",
      "18             5                0\n",
      "19             5                0\n",
      "Fold: 3, Accuracy: 0.3\n",
      "Fold: 4\n",
      "Epoch 1/100   Error=0.174897\n",
      "Epoch 2/100   Error=0.174417\n",
      "Epoch 3/100   Error=0.175116\n",
      "Epoch 4/100   Error=0.175712\n",
      "Epoch 5/100   Error=0.176717\n",
      "Epoch 6/100   Error=0.177296\n",
      "Epoch 7/100   Error=0.181001\n",
      "Stopping early at epoch 7 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             2                0\n",
      "15             3                0\n",
      "16             4                0\n",
      "17             5                0\n",
      "18             5                0\n",
      "19             5                0\n",
      "Fold: 4, Accuracy: 0.3\n",
      "Fold: 5\n",
      "Epoch 1/100   Error=0.174859\n",
      "Epoch 2/100   Error=0.174643\n",
      "Epoch 3/100   Error=0.175984\n",
      "Epoch 4/100   Error=0.178489\n",
      "Epoch 5/100   Error=0.186586\n",
      "Epoch 6/100   Error=0.251589\n",
      "Epoch 7/100   Error=0.274895\n",
      "Stopping early at epoch 7 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              1                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             1                1\n",
      "13             2                1\n",
      "14             2                1\n",
      "15             3                1\n",
      "16             4                1\n",
      "17             5                1\n",
      "18             5                1\n",
      "19             5                1\n",
      "Fold: 5, Accuracy: 0.35\n",
      "Fold: 6\n",
      "Epoch 1/100   Error=0.179180\n",
      "Epoch 2/100   Error=0.186457\n",
      "Epoch 3/100   Error=0.302336\n",
      "Epoch 4/100   Error=0.653709\n",
      "Epoch 5/100   Error=0.703312\n",
      "Epoch 6/100   Error=0.691596\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                5\n",
      "1              0                5\n",
      "2              0                5\n",
      "3              0                5\n",
      "4              0                5\n",
      "5              0                5\n",
      "6              1                5\n",
      "7              1                5\n",
      "8              1                5\n",
      "9              1                5\n",
      "10             1                5\n",
      "11             1                5\n",
      "12             1                5\n",
      "13             2                5\n",
      "14             3                5\n",
      "15             4                5\n",
      "16             5                5\n",
      "17             5                5\n",
      "18             5                5\n",
      "Fold: 6, Accuracy: 0.15789473684210525\n",
      "Fold: 7\n",
      "Epoch 1/100   Error=0.175589\n",
      "Epoch 2/100   Error=0.176015\n",
      "Epoch 3/100   Error=0.176771\n",
      "Epoch 4/100   Error=0.180483\n",
      "Epoch 5/100   Error=0.195928\n",
      "Epoch 6/100   Error=0.393007\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             3                0\n",
      "15             4                0\n",
      "16             5                0\n",
      "17             5                0\n",
      "Fold: 7, Accuracy: 0.3333333333333333\n",
      "Fold: 8\n",
      "Epoch 1/100   Error=0.178520\n",
      "Epoch 2/100   Error=0.181133\n",
      "Epoch 3/100   Error=0.188990\n",
      "Epoch 4/100   Error=0.319448\n",
      "Epoch 5/100   Error=0.425512\n",
      "Epoch 6/100   Error=0.431773\n",
      "Stopping early at epoch 6 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                0\n",
      "1              0                0\n",
      "2              0                0\n",
      "3              0                0\n",
      "4              0                0\n",
      "5              0                0\n",
      "6              1                0\n",
      "7              1                0\n",
      "8              1                0\n",
      "9              1                0\n",
      "10             1                0\n",
      "11             1                0\n",
      "12             1                0\n",
      "13             2                0\n",
      "14             3                0\n",
      "15             5                0\n",
      "16             5                0\n",
      "Fold: 8, Accuracy: 0.35294117647058826\n",
      "Fold: 9\n",
      "Epoch 1/100   Error=0.170627\n",
      "Epoch 2/100   Error=0.169448\n",
      "Epoch 3/100   Error=0.169039\n",
      "Epoch 4/100   Error=0.168235\n",
      "Epoch 5/100   Error=0.167819\n",
      "Epoch 6/100   Error=0.168445\n",
      "Epoch 7/100   Error=0.169297\n",
      "Epoch 8/100   Error=0.172958\n",
      "Epoch 9/100   Error=0.197784\n",
      "Epoch 10/100   Error=0.230440\n",
      "Stopping early at epoch 10 due to no improvement.\n",
      "    Actual Class  Predicted Class\n",
      "0              0                1\n",
      "1              0                1\n",
      "2              0                1\n",
      "3              0                1\n",
      "4              0                1\n",
      "5              0                1\n",
      "6              1                1\n",
      "7              1                1\n",
      "8              1                1\n",
      "9              1                1\n",
      "10             1                1\n",
      "11             1                1\n",
      "12             2                1\n",
      "13             3                1\n",
      "14             5                1\n",
      "15             5                1\n",
      "Fold: 9, Accuracy: 0.375\n",
      "Mean Accuracy across all folds: 0.2911593489070269\n"
     ]
    }
   ],
   "source": [
    "#Main driver class calls all other classes  \n",
    "\n",
    "class Driver:\n",
    "    def __init__(self):\n",
    "        self.DSNames_classification = 'glass', 'soybean-small', 'breast-cancer-wisconsin'\n",
    "        self.DSNames_regression = 'abalone', 'machine', 'forestfires'\n",
    "    \n",
    "    #classification\n",
    "    def main_classification(self):\n",
    "        \n",
    "        #Preprocessing part\n",
    "        #change the dataset number here from 0 to 2\n",
    "        ds = DataSet(self.DSNames_classification[0])\n",
    "        ds.type = 'Classification'\n",
    "        ds_reader = Dataset_Reader()\n",
    "        ds_reader.read_data_file(ds)\n",
    "            \n",
    "        pp = PreProcess(ds)\n",
    "        pp.split_tuning_data_classification(ds)\n",
    "        pp.split_data_classification(ds)\n",
    "        \n",
    "        cn = ClassificationNet()\n",
    "        cn.tuneLearningRate(ds, 2)\n",
    "        cn.mainFunction(ds, 0)\n",
    "        cn.mainFunction(ds, 1)\n",
    "        cn.mainFunction(ds, 2)\n",
    "        \n",
    "       \n",
    "        \n",
    "    #Regression\n",
    "    def main_regression(self):\n",
    "        #change the dataset number here from 0 to 2\n",
    "        ds = DataSet(self.DSNames_regression[1])\n",
    "        ds.type = 'Regression'\n",
    "        ds_reader = Dataset_Reader()\n",
    "        ds_reader.read_data_file(ds)\n",
    "        \n",
    "        pp = PreProcess(ds)\n",
    "        pp.split_tuning_data_regression(ds)\n",
    "        pp.split_data_regression(ds)\n",
    "        \n",
    "        rn = RegressionNet()\n",
    "        rn.tuneLearningRate(ds, 2)\n",
    "        rn.mainFunction(ds, 0)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#calling the driver class here.    \n",
    "dr = Driver()\n",
    "dr.main_classification() \n",
    "#dr.main_regression()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ffc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
